{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks\n"
     ]
    }
   ],
   "source": [
    "cd /notebooks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixiedust database opened successfully\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style=\"margin:10px\">\n",
       "            <a href=\"https://github.com/ibm-watson-data-lab/pixiedust\" target=\"_new\">\n",
       "                <img src=\"https://github.com/ibm-watson-data-lab/pixiedust/raw/master/docs/_static/pd_icon32.png\" style=\"float:left;margin-right:10px\"/>\n",
       "            </a>\n",
       "            <span>Pixiedust version 1.1.15</span>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *   # Quick accesss to NLP functionality\n",
    "\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.sampler import Sampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import time\n",
    "import importlib\n",
    "import pixiedust\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = Path('/data/WS/')\n",
    "PATH = Path('/data/sav/WS/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://dbressbuck/data/WS/evaluate.csv to ../data/WS/evaluate.csv\n",
      "download: s3://dbressbuck/data/WS/train.csv to ../data/WS/train.csv\n",
      "download: s3://dbressbuck/data/WS/classifier_weights_001.pth to ../data/WS/classifier_weights_001.pth\n",
      "download: s3://dbressbuck/data/WS/sent140_training.csv to ../data/WS/sent140_training.csv\n"
     ]
    }
   ],
   "source": [
    "#DOWNLOAD THE DATA\n",
    "!aws s3 cp --recursive s3://dbressbuck/data/WS /data/WS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(750000, 2)\n",
      "         sentiment                                            content\n",
      "477646           0  todays plans have been messed up as now not fe...\n",
      "133647           0  Nose is completely stuffed and throat is sore ...\n",
      "1196363          4                             Zero tolerence policy \n",
      "64522            0  How in the name of all that is holy did it get...\n",
      "523066           0  @tlmasonaea I wish I could, but I live a bit t...\n"
     ]
    }
   ],
   "source": [
    "#load data, look at size of training sets and test set, look at some samples\n",
    "df_trn = pd.read_csv(DATAPATH/'sent140_training.csv',encoding = \"ISO-8859-1\",names=['sentiment', 'id', 'date','flag','user','content'])\n",
    "df_trn= df_trn[['sentiment','content']]\n",
    "get_these=np.random.permutation(np.shape(df_trn)[0])\n",
    "df_trn=df_trn.iloc[get_these[:750000]]#take a sample of 750K, due to time constraints\n",
    "\n",
    "print(np.shape(df_trn))\n",
    "print(df_trn.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(743815, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132481</th>\n",
       "      <td>0</td>\n",
       "      <td>Headache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340713</th>\n",
       "      <td>0</td>\n",
       "      <td>isPlayer Has Died! Sorry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498708</th>\n",
       "      <td>0</td>\n",
       "      <td>I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220156</th>\n",
       "      <td>0</td>\n",
       "      <td>I have a headache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650089</th>\n",
       "      <td>0</td>\n",
       "      <td>Jogging, isnt REALLY that cool, especially if ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment                                            content\n",
       "132481          0                                          Headache \n",
       "340713          0                          isPlayer Has Died! Sorry \n",
       "498708          0                                        I miss you \n",
       "220156          0                                 I have a headache \n",
       "650089          0  Jogging, isnt REALLY that cool, especially if ..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#there are some duplicate tweets... Take a quick look at them\n",
    "print(np.shape(df_trn[~df_trn['content'].duplicated()]))\n",
    "df_duplicated=df_trn[df_trn['content'].duplicated()]\n",
    "df_duplicated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(743815, 2)\n"
     ]
    }
   ],
   "source": [
    "#remove duplicates... no reason to include these in training\n",
    "df_trn=df_trn[~df_trn['content'].duplicated()]\n",
    "print(np.shape(df_trn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sentiment                                            content  str_len\n",
      "477646           0  todays plans have been messed up as now not fe...      101\n",
      "133647           0  Nose is completely stuffed and throat is sore ...       85\n",
      "1196363          4                             Zero tolerence policy        22\n",
      "64522            0  How in the name of all that is holy did it get...       58\n",
      "523066           0  @tlmasonaea I wish I could, but I live a bit t...       62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f3a484273c8>]], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create column to take a look at length of tweets, and create graph of distribution\n",
    "df_trn['str_len']=df_trn['content'].str.len()\n",
    "print(df_trn.head())\n",
    "df_trn.hist(column='str_len', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time permitting, investigate if there's anything peculiar \n",
    "    #about the spike at the right side of the graph above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([371759.,      0.,      0.,      0.,      0.,      0.,      0.,      0.,      0., 372056.]),\n",
       " array([0. , 0.4, 0.8, 1.2, 1.6, 2. , 2.4, 2.8, 3.2, 3.6, 4. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#look at distribution of labels... \n",
    "#2 categories, approximately equal number each\n",
    "print(df_trn['sentiment'].unique()) #unique labels\n",
    "plt.hist(list(df_trn['sentiment']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build new training set for semi-supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal: simulate common situation of: 1) Small labeled dataset, 2) Much larger unlabeled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled set size: 14876\n",
      "unlabeled set size: 728939\n"
     ]
    }
   ],
   "source": [
    "#grab 2% of the dataset as our labeled dataset\n",
    "#the other 98% will serve as our 'unlabeled dataset'\n",
    "    #but we'll still keep the labels\n",
    "get_these=np.random.permutation(np.shape(df_trn)[0])\n",
    "split_here=round(.02*np.shape(df_trn)[0])\n",
    "df_labeled=df_trn.iloc[get_these[:split_here]]\n",
    "df_unlabeled=df_trn.iloc[get_these[split_here:]]\n",
    "print('labeled set size:', np.shape(df_labeled)[0])\n",
    "print('unlabeled set size:',np.shape(df_unlabeled)[0])\n",
    "assert np.shape(df_labeled)[0]+np.shape(df_unlabeled)[0]==np.shape(df_trn)[0], 'lengths dont add up'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set size: 2231\n",
      "valid set size: 2232\n",
      "train set size: 10413\n",
      "larger set size: 739352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#create train, valid, and test set from labeled data\n",
    "get_these=np.random.permutation(np.shape(df_labeled)[0])\n",
    "split_here1=round(.15*np.shape(df_labeled)[0])\n",
    "split_here2=round(.3*np.shape(df_labeled)[0])\n",
    "df_labeled_test=df_labeled.iloc[get_these[:split_here1]]\n",
    "df_labeled_valid=df_labeled.iloc[get_these[split_here1:split_here2]]\n",
    "df_labeled_trn=df_labeled.iloc[get_these[split_here2:]]\n",
    "print('test set size:', np.shape(df_labeled_test)[0])\n",
    "print('valid set size:', np.shape(df_labeled_valid)[0])\n",
    "print('train set size:',np.shape(df_labeled_trn)[0])\n",
    "assert np.shape(df_labeled_test)[0]+np.shape(df_labeled_valid)[0]+np.shape(df_labeled_trn)[0]==np.shape(df_labeled)[0], 'lengths dont add up'\n",
    "\n",
    "\n",
    "\n",
    "df_labeled_valid['is_valid']=1\n",
    "df_labeled_trn['is_valid']=0\n",
    "df_unlabeled['is_valid']=0\n",
    "\n",
    "#create a dataset made of df_labeled_trn and df_unlabeled\n",
    "#this simulates situation where we have a much larger set of labeled data\n",
    "df_large=pd.concat([df_labeled_trn,df_unlabeled])\n",
    "\n",
    "print('larger set size:',np.shape(df_large)[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         sentiment                                            content  \\\n",
      "877259           4  Talk about Different  I like this one  ? http:...   \n",
      "1434762          4  Got a job at KFC, taking in some new hobbies, ...   \n",
      "139399           0  @HeathCastor I dunno? I never been to a club. ...   \n",
      "53857            0                                 My phone is dying    \n",
      "976136           4                  is watching ellen degeneres show    \n",
      "\n",
      "         str_len  is_valid  \n",
      "877259        62         0  \n",
      "1434762       84         0  \n",
      "139399       116         0  \n",
      "53857         18         0  \n",
      "976136        33         0  \n",
      "         sentiment                                            content  \\\n",
      "299472           0  Ditching school. Im gonna sleep. =P LOL. Watch...   \n",
      "611166           0  @bear_smooter Even with a bottle of wine? That...   \n",
      "777080           0  Running the M/V Donald Creppel *sigh* for the ...   \n",
      "1414226          4  @myMisericordia oH I would love to see the dog...   \n",
      "1109583          4  What a perfect day... Sunshine, 23'C, 4-5 Bft ...   \n",
      "\n",
      "         str_len  is_valid  \n",
      "299472        91         0  \n",
      "611166        58         0  \n",
      "777080       112         0  \n",
      "1414226       63         0  \n",
      "1109583      137         0  \n",
      "size of each sample: 12645\n"
     ]
    }
   ],
   "source": [
    "#For tri-training, we need 3 bootstrapped samples from the labeled train set\n",
    "#That is, we need random sampling with replacement\n",
    "sample_n=np.shape(df_labeled_trn)[0]\n",
    "\n",
    "df_labeled_trn_s1=df_labeled_trn.sample(n=sample_n,replace=True)\n",
    "df_labeled_trn_s2=df_labeled_trn.sample(n=sample_n,replace=True)\n",
    "df_labeled_trn_s3=df_labeled_trn.sample(n=sample_n,replace=True)\n",
    "\n",
    "#add in the validation set\n",
    "df_labeled_trn_s1=pd.concat([df_labeled_trn_s1,df_labeled_valid])\n",
    "df_labeled_trn_s2=pd.concat([df_labeled_trn_s2,df_labeled_valid])\n",
    "df_labeled_trn_s3=pd.concat([df_labeled_trn_s3,df_labeled_valid])\n",
    "df_large=pd.concat([df_large,df_labeled_valid])\n",
    "\n",
    "print(df_labeled_trn_s1.head())\n",
    "print(df_labeled_trn_s2.head())\n",
    "\n",
    "print('size of each sample:',np.shape(df_labeled_trn_s1)[0])\n",
    "\n",
    "assert np.shape(df_labeled_trn_s1)[0]==np.shape(df_labeled_trn_s2)[0]\n",
    "assert np.shape(df_labeled_trn_s1)[0]==np.shape(df_labeled_trn_s3)[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save all of our datasets!\n",
    "\n",
    "df_trn.to_csv(DATAPATH/'df_full.csv', index=False)\n",
    "df_large.to_csv(DATAPATH/'df_large.csv', index=False)\n",
    "\n",
    "df_labeled.to_csv(DATAPATH/'df_labeled.csv', index=False)\n",
    "df_unlabeled.to_csv(DATAPATH/'df_unlabeled.csv', index=False)\n",
    "\n",
    "df_labeled_trn.to_csv(DATAPATH/'train_labeled.csv', index=False)\n",
    "df_labeled_valid.to_csv(DATAPATH/'valid_labeled.csv', index=False)\n",
    "df_labeled_test.to_csv(DATAPATH/'test_labeled.csv', index=False)\n",
    "\n",
    "df_labeled_trn_s1.to_csv(DATAPATH/'train_labeled_s1.csv', index=False)\n",
    "df_labeled_trn_s2.to_csv(DATAPATH/'train_labeled_s2.csv', index=False)\n",
    "df_labeled_trn_s3.to_csv(DATAPATH/'train_labeled_s3.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and run language model on the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set momentum values\n",
    "moms = (0.8,0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#language model data object\n",
    "data_lm = TextLMDataBunch.from_csv(DATAPATH, 'df_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4.498345</td>\n",
       "      <td>4.264409</td>\n",
       "      <td>0.251641</td>\n",
       "      <td>13:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.341630</td>\n",
       "      <td>4.138883</td>\n",
       "      <td>0.265268</td>\n",
       "      <td>13:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.232799</td>\n",
       "      <td>4.069581</td>\n",
       "      <td>0.272389</td>\n",
       "      <td>13:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.140287</td>\n",
       "      <td>4.050951</td>\n",
       "      <td>0.274442</td>\n",
       "      <td>13:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This is using fast.ai's pretrained language model:\n",
    "#Model pretrained on wikitext103 dataset: \n",
    "    #https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/\n",
    "    #~100M tokens, ~270K vocab\n",
    "#Model based on Merity/Socher's AWD-LSTM quasi-recurrent neural network (QRNN)\n",
    "    #https://arxiv.org/abs/1708.02182\n",
    "learn = language_model_learner(data_lm, AWD_LSTM)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, slice(1e-2), moms=moms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save weights from language model\n",
    "learn.save_encoder('enc_LM_sent140')\n",
    "itos=data_lm.train_ds.vocab.itos# the vocab\n",
    "pickle.dump(itos, open(DATAPATH/'itos.pkl', 'wb'))#save the vocab\n",
    "#itos2 = pickle.load(open(DATAPATH/'itos.pkl', 'rb')) #load the vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and run first round of classification models for tri-training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This involves building and training three separate models, each based on one of the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create datasets for classification models\n",
    "\n",
    "#First some preprocessing for main training set:\n",
    "df_test=pd.read_csv(DATAPATH/'valid_labeled.csv')\n",
    "df_test['is_valid']=1\n",
    "df_tmp = pd.read_csv(DATAPATH/'train_labeled.csv')\n",
    "df_tmp['is_valid']=0\n",
    "df_tmp=pd.concat([df_tmp,df_test])\n",
    "df_tmp.to_csv(DATAPATH/'df_tmp.csv', index=False)\n",
    "tmplist=TextList.from_csv(DATAPATH, 'df_tmp.csv', cols='content', vocab=data_lm.train_ds.vocab)\n",
    "data_clas_main = (tmplist\n",
    "                .split_from_df(col='is_valid')\n",
    "                .label_from_df(cols='sentiment')#.add_test(test_list)\n",
    "                .databunch(bs=40))\n",
    "\n",
    "\n",
    "\n",
    "#Now for the samples...\n",
    "text_train_list_s1=TextList.from_csv(DATAPATH, 'train_labeled_s1.csv', cols='content', vocab=data_lm.train_ds.vocab)\n",
    "text_train_list_s2=TextList.from_csv(DATAPATH, 'train_labeled_s2.csv', cols='content', vocab=data_lm.train_ds.vocab)\n",
    "text_train_list_s3=TextList.from_csv(DATAPATH, 'train_labeled_s3.csv', cols='content', vocab=data_lm.train_ds.vocab)\n",
    "text_test_list=TextList.from_csv(DATAPATH, 'test_labeled.csv', cols='content', vocab=data_lm.train_ds.vocab)\n",
    "\n",
    "text_large_list=TextList.from_csv(DATAPATH, 'df_large.csv', cols='content', vocab=data_lm.train_ds.vocab)\n",
    "\n",
    "#The datasets for the 3 samples\n",
    "data_clas_s1 = (text_train_list_s1\n",
    "                .split_from_df(col='is_valid')\n",
    "                .label_from_df(cols='sentiment')\n",
    "                .add_test(text_test_list)\n",
    "                .databunch(bs=40))\n",
    "\n",
    "data_clas_s2 = (text_train_list_s2\n",
    "                .split_from_df(col='is_valid')\n",
    "                .label_from_df(cols='sentiment')\n",
    "                .add_test(text_test_list)\n",
    "                .databunch(bs=40))\n",
    "\n",
    "data_clas_s3 = (text_train_list_s3\n",
    "                .split_from_df(col='is_valid')\n",
    "                .label_from_df(cols='sentiment')\n",
    "                .add_test(text_test_list)\n",
    "                .databunch(bs=40))\n",
    "\n",
    "#Data for the much larger dataset\n",
    "data_clas_large = (text_large_list\n",
    "                .split_from_df(col='is_valid')\n",
    "                .label_from_df(cols='sentiment')\n",
    "                .add_test(text_test_list)\n",
    "                .databunch(bs=40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.557100</td>\n",
       "      <td>0.473547</td>\n",
       "      <td>0.778674</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.538399</td>\n",
       "      <td>0.469144</td>\n",
       "      <td>0.786290</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.528870</td>\n",
       "      <td>0.458265</td>\n",
       "      <td>0.793011</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.522673</td>\n",
       "      <td>0.450327</td>\n",
       "      <td>0.797043</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Classification model based on Howard/Ruder's ULMFiT approach:\n",
    "    #https://arxiv.org/abs/1801.06146\n",
    "#Start with pretrained LM and fine-tune on dataset as above\n",
    "#Keep the LM's \"encoder\" spine, but replace the head of the NN with a new network that predicts class\n",
    "#This approach utilizes transfer learning to enhance the classifier's performance\n",
    "#Also using one_cycle superconvergence: modify the learning rate and momentum value during training\n",
    "    #Ramp up then down the LR, while ramping down then up the momentum\n",
    "    #Significantly reduces training time and improves performance\n",
    "    #From Leslie Smith's paper: https://arxiv.org/pdf/1803.09820.pdf\n",
    "\n",
    "learn = text_classifier_learner(data_clas_s1, AWD_LSTM)\n",
    "learn.load_encoder('enc_LM_sent140')#load in the weights from the LM encoder\n",
    "learn.fit_one_cycle(4, moms=moms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.504981</td>\n",
       "      <td>0.447752</td>\n",
       "      <td>0.795251</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.502337</td>\n",
       "      <td>0.441159</td>\n",
       "      <td>0.802419</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.485947</td>\n",
       "      <td>0.434843</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.464925</td>\n",
       "      <td>0.430869</td>\n",
       "      <td>0.800179</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.478139</td>\n",
       "      <td>0.427724</td>\n",
       "      <td>0.801971</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.441130</td>\n",
       "      <td>0.423802</td>\n",
       "      <td>0.807796</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.435809</td>\n",
       "      <td>0.424800</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.436540</td>\n",
       "      <td>0.423292</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Unfreeze all the layers and continue training:\n",
    "#Above, all the layers except for the last layer is frozen\n",
    "    #Idea is that \"encoder\" spine from the LM is fairly well-tuned, so only need to train the classifier head\n",
    "#Once head has been trained, now we can train all the layers of the network\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(8, slice(1e-5,1e-3), moms=moms)\n",
    "learn.save('s1_12e_unfreeze_001')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.553158</td>\n",
       "      <td>0.479018</td>\n",
       "      <td>0.780018</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.529465</td>\n",
       "      <td>0.456275</td>\n",
       "      <td>0.788979</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.511834</td>\n",
       "      <td>0.449919</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.511102</td>\n",
       "      <td>0.446709</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.512473</td>\n",
       "      <td>0.443832</td>\n",
       "      <td>0.798835</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.496623</td>\n",
       "      <td>0.444081</td>\n",
       "      <td>0.794803</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.498999</td>\n",
       "      <td>0.439865</td>\n",
       "      <td>0.799731</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.480570</td>\n",
       "      <td>0.436788</td>\n",
       "      <td>0.801075</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.471058</td>\n",
       "      <td>0.432162</td>\n",
       "      <td>0.799283</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.449307</td>\n",
       "      <td>0.433056</td>\n",
       "      <td>0.804659</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.441979</td>\n",
       "      <td>0.432702</td>\n",
       "      <td>0.798387</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.438534</td>\n",
       "      <td>0.431688</td>\n",
       "      <td>0.799283</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Do same for s2\n",
    "learn = text_classifier_learner(data_clas_s2, AWD_LSTM)\n",
    "learn.load_encoder('enc_LM_sent140')#load in the weights from the LM encoder\n",
    "learn.fit_one_cycle(4, moms=moms)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(8, slice(1e-5,1e-3), moms=moms)\n",
    "learn.save('s2_12e_unfreeze_001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.562157</td>\n",
       "      <td>0.463909</td>\n",
       "      <td>0.788082</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.537904</td>\n",
       "      <td>0.463287</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.531749</td>\n",
       "      <td>0.453772</td>\n",
       "      <td>0.801075</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.515903</td>\n",
       "      <td>0.447557</td>\n",
       "      <td>0.801523</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.505817</td>\n",
       "      <td>0.446676</td>\n",
       "      <td>0.799283</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.511284</td>\n",
       "      <td>0.441550</td>\n",
       "      <td>0.801075</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.505528</td>\n",
       "      <td>0.438899</td>\n",
       "      <td>0.801523</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.484266</td>\n",
       "      <td>0.431523</td>\n",
       "      <td>0.801523</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.476524</td>\n",
       "      <td>0.427838</td>\n",
       "      <td>0.803315</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.461210</td>\n",
       "      <td>0.424891</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>00:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.437228</td>\n",
       "      <td>0.423725</td>\n",
       "      <td>0.808692</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.437958</td>\n",
       "      <td>0.423919</td>\n",
       "      <td>0.814964</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Do same for s3\n",
    "learn = text_classifier_learner(data_clas_s3, AWD_LSTM)\n",
    "learn.load_encoder('enc_LM_sent140')#load in the weights from the LM encoder\n",
    "learn.fit_one_cycle(4, moms=moms)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(8, slice(1e-5,1e-3), moms=moms)\n",
    "learn.save('s3_12e_unfreeze_001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.513515</td>\n",
       "      <td>0.425657</td>\n",
       "      <td>0.809588</td>\n",
       "      <td>07:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.514032</td>\n",
       "      <td>0.416941</td>\n",
       "      <td>0.812276</td>\n",
       "      <td>07:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.496843</td>\n",
       "      <td>0.411278</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>07:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.498127</td>\n",
       "      <td>0.408943</td>\n",
       "      <td>0.819892</td>\n",
       "      <td>07:23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.473285</td>\n",
       "      <td>0.385465</td>\n",
       "      <td>0.823477</td>\n",
       "      <td>19:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.442043</td>\n",
       "      <td>0.363186</td>\n",
       "      <td>0.838262</td>\n",
       "      <td>18:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.396280</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.848118</td>\n",
       "      <td>18:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.401837</td>\n",
       "      <td>0.337543</td>\n",
       "      <td>0.859767</td>\n",
       "      <td>18:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.386306</td>\n",
       "      <td>0.332238</td>\n",
       "      <td>0.861559</td>\n",
       "      <td>19:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.388812</td>\n",
       "      <td>0.331113</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>19:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.383931</td>\n",
       "      <td>0.326626</td>\n",
       "      <td>0.864695</td>\n",
       "      <td>19:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.398179</td>\n",
       "      <td>0.325612</td>\n",
       "      <td>0.866935</td>\n",
       "      <td>18:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Do same for large... \n",
    "#This simulates the situation where we have a much larger fully labeled dataset to work with\n",
    "#Performance of this model is just being used as a benchmark...\n",
    "    #it should be an upper bound for how well we can do with a semi-supervised approach\n",
    "learn = text_classifier_learner(data_clas_large, AWD_LSTM)\n",
    "learn.load_encoder('enc_LM_sent140')#load in the weights from the LM encoder\n",
    "learn.fit_one_cycle(4, moms=moms)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(8, slice(1e-5,1e-3), moms=moms)\n",
    "learn.save('large_12e_unfreeze_001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.550273</td>\n",
       "      <td>0.481037</td>\n",
       "      <td>0.775538</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.546122</td>\n",
       "      <td>0.460460</td>\n",
       "      <td>0.786290</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.528236</td>\n",
       "      <td>0.448869</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.531728</td>\n",
       "      <td>0.443203</td>\n",
       "      <td>0.800627</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.523767</td>\n",
       "      <td>0.439798</td>\n",
       "      <td>0.801971</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.520413</td>\n",
       "      <td>0.436762</td>\n",
       "      <td>0.803315</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.500631</td>\n",
       "      <td>0.424167</td>\n",
       "      <td>0.812724</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.506463</td>\n",
       "      <td>0.422609</td>\n",
       "      <td>0.810484</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.491173</td>\n",
       "      <td>0.418874</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.489887</td>\n",
       "      <td>0.418407</td>\n",
       "      <td>0.813172</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.463318</td>\n",
       "      <td>0.416468</td>\n",
       "      <td>0.812724</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.491464</td>\n",
       "      <td>0.413754</td>\n",
       "      <td>0.814964</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Do same for main (unsampled) training set... \n",
    "learn = text_classifier_learner(data_clas_main, AWD_LSTM)\n",
    "learn.load_encoder('enc_LM_sent140')#load in the weights from the LM encoder\n",
    "learn.fit_one_cycle(4, moms=moms)\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(8, slice(1e-5,1e-3), moms=moms)\n",
    "learn.save('main_12e_unfreeze_001')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions on unlabeled data from all three samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a data structure for making predictions on the unlabeled data\n",
    "df_test=pd.read_csv(DATAPATH/'df_unlabeled.csv')\n",
    "df_test['is_valid']=1\n",
    "\n",
    "df_tmp = pd.read_csv(DATAPATH/'train_labeled_s1.csv')\n",
    "df_tmp=df_tmp[df_tmp['is_valid']==0]\n",
    "df_tmp=pd.concat([df_tmp,df_test])\n",
    "\n",
    "df_tmp.to_csv(DATAPATH/'df_tmp.csv', index=False)\n",
    "tmplist=TextList.from_csv(DATAPATH, 'df_tmp.csv', cols='content', vocab=data_lm.train_ds.vocab)\n",
    "data_tmp = (tmplist\n",
    "                .split_from_df(col='is_valid')\n",
    "                .label_from_df(cols='sentiment')\n",
    "                .databunch(bs=40))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions on the unlabeled data, for all three samples\n",
    "learn = text_classifier_learner(data_tmp, AWD_LSTM)\n",
    "learn.load('s1_12e_unfreeze_001')\n",
    "predictions_s1=learn.get_preds(DatasetType.Valid,ordered=True)\n",
    "pickle.dump(predictions_s1, open(DATAPATH/'predictions_s1.pkl', 'wb'))#save the predictions\n",
    "learn.load('s2_12e_unfreeze_001')\n",
    "predictions_s2=learn.get_preds(DatasetType.Valid,ordered=True)\n",
    "pickle.dump(predictions_s2, open(DATAPATH/'predictions_s2.pkl', 'wb'))#save the predictions\n",
    "learn.load('s3_12e_unfreeze_001')\n",
    "predictions_s3=learn.get_preds(DatasetType.Valid,ordered=True)\n",
    "pickle.dump(predictions_s3, open(DATAPATH/'predictions_s3.pkl', 'wb'))#save the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions on the unlabeled data, for the main data's model\n",
    "learn = text_classifier_learner(data_tmp, AWD_LSTM)\n",
    "learn.load('main_12e_unfreeze_001')\n",
    "predictions_main=learn.get_preds(DatasetType.Valid,ordered=True)\n",
    "pickle.dump(predictions_main, open(DATAPATH/'predictions_main.pkl', 'wb'))#save the predictions\n",
    "#predictions_main = pickle.load(open(DATAPATH/'predictions_main.pkl', 'rb')) #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert prediction probabilities into np arrays, and concatenate\n",
    "predictions_probs=np.stack([predictions_s1[0].cpu().numpy()[:,0],\n",
    "                            predictions_s2[0].cpu().numpy()[:,0],\n",
    "                            predictions_s3[0].cpu().numpy()[:,0]],1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Do various pre-processing useful for deciding which unlabeled examples\n",
    "    # go to which samples\n",
    "\n",
    "#predictions for each of 3 samples\n",
    "predictions_predtargets=(predictions_probs>.5).astype(int)\n",
    "#average prediction\n",
    "ave_pred=np.mean(predictions_predtargets,axis=1)\n",
    "#get average probability over 3 samples:\n",
    "ave_prob=np.mean(predictions_probs,axis=1)\n",
    "#get standard deviation over 3 samples:\n",
    "std_prob=np.std(predictions_probs,axis=1)\n",
    "#get biggest differences bw ave of 2 and the third\n",
    "dif_prob_12m3=np.mean(predictions_probs[:,[0,1]],axis=1)-predictions_probs[:,2]\n",
    "dif_prob_13m2=np.mean(predictions_probs[:,[0,2]],axis=1)-predictions_probs[:,1]\n",
    "dif_prob_23m1=np.mean(predictions_probs[:,[1,2]],axis=1)-predictions_probs[:,0]\n",
    "#get individual samples probs\n",
    "s1_prediction_probs=predictions_probs[:,0]\n",
    "s2_prediction_probs=predictions_probs[:,1]\n",
    "s3_prediction_probs=predictions_probs[:,2]\n",
    "#get averages between pairings of 2 samples\n",
    "ave_prob12=np.mean(predictions_probs[:,[0,1]],axis=1)\n",
    "ave_prob13=np.mean(predictions_probs[:,[0,2]],axis=1)\n",
    "ave_prob23=np.mean(predictions_probs[:,[1,2]],axis=1)\n",
    "#set target to 1 or 0 based on ave_pred:\n",
    "ave_prob_target=np.round(ave_pred).astype('int')\n",
    "#get the indices of the max and min values\n",
    "probs_max_ind=np.argmax(predictions_probs,axis=1)\n",
    "probs_min_ind=np.argmin(predictions_probs,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard deviation between three models prediction labels:  0.04928733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2.00000e+00, 4.00000e+00, 7.00000e+00, 1.10000e+01, 2.50000e+01, 4.60000e+01, 1.07000e+02, 1.62000e+02,\n",
       "        2.42000e+02, 4.66000e+02, 7.45000e+02, 1.23100e+03, 2.06000e+03, 3.54400e+03, 5.55200e+03, 9.04200e+03,\n",
       "        1.38700e+04, 2.11900e+04, 3.08680e+04, 4.37740e+04, 6.04790e+04, 7.90900e+04, 1.08859e+05, 8.47090e+04,\n",
       "        6.69870e+04, 5.31460e+04, 4.19600e+04, 3.12800e+04, 2.26760e+04, 1.59200e+04, 1.07640e+04, 7.08400e+03,\n",
       "        4.75800e+03, 3.28000e+03, 1.91100e+03, 1.23400e+03, 7.42000e+02, 4.56000e+02, 2.84000e+02, 1.50000e+02,\n",
       "        8.60000e+01, 4.70000e+01, 3.40000e+01, 2.00000e+01, 1.70000e+01, 4.00000e+00, 4.00000e+00, 2.00000e+00,\n",
       "        6.00000e+00, 2.00000e+00]),\n",
       " array([-0.532669, -0.509105, -0.48554 , -0.461975, ...,  0.574874,  0.598439,  0.622003,  0.645568], dtype=float32),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the difference in predicted label between\n",
    "    #a single sample and the average of the other two samples\n",
    "#The vast majority of generated predictions are very similar between the three models \n",
    "print('standard deviation between three models prediction labels: ',np.mean(np.std(predictions_probs,axis=1)))\n",
    "plt.hist(dif_prob_12m3,50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8918., 15396., 15408., 14118., ..., 12816., 13178., 12885.,  7376.]),\n",
       " array([2.631912e-04, 1.025930e-02, 2.025542e-02, 3.025153e-02, ..., 9.698861e-01, 9.798822e-01, 9.898784e-01,\n",
       "        9.998745e-01], dtype=float32),\n",
       " <a list of 100 Patch objects>)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#The distribution of the generated probabilities\n",
    "plt.hist(predictions_main[0].cpu().numpy()[:,0],100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate situation of paying for most important labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29999,)\n",
      "(30000,)\n",
      "(30000,)\n",
      "(30000,)\n",
      "(30000,)\n"
     ]
    }
   ],
   "source": [
    "#for main... test effect of adding in 30K examples of TRUE labels from:\n",
    "    #1) It's most confident predictions\n",
    "    #2) It's least confident predictions\n",
    "    #3) It's somewhat confident predictions (i.e. .25, .75) \n",
    "    #4) A random sampling\n",
    "    #5) A random sampling f/ .25 to .75\n",
    "how_many=15000\n",
    "predictions_main = pickle.load(open(DATAPATH/'predictions_main.pkl', 'rb')) #\n",
    "predictions_main_tmp=predictions_main[0].cpu().numpy()[:,0]\n",
    "targets_tmp=predictions_main[1].cpu().numpy()\n",
    "#most confident\n",
    "predictions_main_tmp_sorted=np.sort(predictions_main_tmp)\n",
    "lowthresh=predictions_main_tmp_sorted[how_many]\n",
    "highthresh=predictions_main_tmp_sorted[len(absdif_f_p5)-how_many]\n",
    "get_these_most=np.zeros(len(absdif_f_p5))\n",
    "get_these_most[np.logical_or(predictions_main_tmp<lowthresh,predictions_main_tmp>highthresh)]=1\n",
    "get_these_most=get_these_most.astype(bool)\n",
    "print(np.shape(predictions_main_tmp[get_these_most]))\n",
    "#least confident\n",
    "absdif_f_p5=np.abs(.5-predictions_main_tmp)\n",
    "absdif_f_p5_sorted=np.sort(absdif_f_p5)\n",
    "lowthresh=absdif_f_p5_sorted[how_many*2]\n",
    "get_these_least=np.zeros(len(absdif_f_p5))\n",
    "get_these_least[np.logical_and(predictions_main_tmp>.5-lowthresh,predictions_main_tmp<.5+lowthresh)]=1\n",
    "get_these_least=get_these_least.astype(bool)\n",
    "print(np.shape(predictions_main_tmp[get_these_least]))\n",
    "#somewhat confident predictions (i.e. .25, .75) \n",
    "get_these_somewhat=np.zeros(len(absdif_f_p5))\n",
    "absdif_f_p25=np.abs(.25-predictions_main_tmp)\n",
    "absdif_f_p25_sorted=np.sort(absdif_f_p25)\n",
    "lowthresh=absdif_f_p25_sorted[how_many]\n",
    "get_these_somewhat[np.logical_and(predictions_main_tmp>.25-lowthresh,predictions_main_tmp<.25+lowthresh)]=1\n",
    "absdif_f_p75=np.abs(.75-predictions_main_tmp)\n",
    "absdif_f_p75_sorted=np.sort(absdif_f_p75)\n",
    "lowthresh=absdif_f_p75_sorted[how_many]\n",
    "get_these_somewhat[np.logical_and(predictions_main_tmp>.75-lowthresh,predictions_main_tmp<.75+lowthresh)]=1\n",
    "get_these_somewhat=get_these_somewhat.astype(bool)\n",
    "print(np.shape(predictions_main_tmp[get_these_somewhat]))\n",
    "#random sampling\n",
    "get_these_rand=np.zeros(len(absdif_f_p5))\n",
    "get_these_rand[np.random.permutation(len(absdif_f_p5))[:how_many*2]]=1\n",
    "get_these_rand=get_these_rand.astype(bool)                 \n",
    "print(np.shape(predictions_main_tmp[get_these_rand]))\n",
    "#random sampling f/ .25 to .75\n",
    "rand_indices=np.array(list(range(len(absdif_f_p5))))\n",
    "rand_indices=rand_indices[np.logical_and(predictions_main_tmp>.25,predictions_main_tmp<.75)][:how_many*2]\n",
    "get_these_randsome=np.zeros(len(absdif_f_p5))\n",
    "get_these_randsome[rand_indices]=1\n",
    "get_these_randsome=get_these_randsome.astype(bool)                 \n",
    "print(np.shape(predictions_main_tmp[get_these_randsome]))\n",
    "#plt.hist(predictions_main_tmp[get_these_randsome],50)\n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.482997</td>\n",
       "      <td>0.416772</td>\n",
       "      <td>0.811380</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.466325</td>\n",
       "      <td>0.409586</td>\n",
       "      <td>0.814964</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.457923</td>\n",
       "      <td>0.407707</td>\n",
       "      <td>0.816308</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.459724</td>\n",
       "      <td>0.409453</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#no additional labels\n",
    "#no change in accuracy... 81.4 to 81.4\n",
    "df_valid=pd.read_csv(DATAPATH/'valid_labeled.csv')\n",
    "df_valid['is_valid']=1\n",
    "df_tmp = pd.read_csv(DATAPATH/'train_labeled.csv')\n",
    "df_tmp['is_valid']=0\n",
    "df_tmp=pd.concat([df_tmp,df_valid])\n",
    "\n",
    "df_tmp.to_csv(DATAPATH/'df_tmp.csv', index=False)\n",
    "tmplist=TextList.from_csv(DATAPATH, 'df_tmp.csv', cols='content', vocab=data_lm.train_ds.vocab)\n",
    "data_clas_main = (tmplist\n",
    "                .split_from_df(col='is_valid')\n",
    "                .label_from_df(cols='sentiment')#.add_test(test_list)\n",
    "                .databunch(bs=40))\n",
    "\n",
    "learn = text_classifier_learner(data_clas_main, AWD_LSTM)\n",
    "learn.load('main_12e_unfreeze_001')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, slice(1e-5,1e-3), moms=moms)\n",
    "learn.save('main_16e_noadd_001')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.178386</td>\n",
       "      <td>0.429605</td>\n",
       "      <td>0.801523</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.213697</td>\n",
       "      <td>0.421999</td>\n",
       "      <td>0.810484</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.171913</td>\n",
       "      <td>0.420076</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>01:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.177001</td>\n",
       "      <td>0.417598</td>\n",
       "      <td>0.802867</td>\n",
       "      <td>01:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#add most confident labels\n",
    "\n",
    "#OUTCOME:\n",
    "#Training loss drastically decreases\n",
    "#Validation loss decreases: .423 to 0.417\n",
    "#Slight overfitting: validation accuracy decreases slightly (even though loss decreased as well)\n",
    "    #81.4 to 80.3\n",
    "\n",
    "df_test=pd.read_csv(DATAPATH/'df_unlabeled.csv')\n",
    "df_test_tmp=df_test.iloc[get_these_most]\n",
    "df_test_tmp['is_valid']=0\n",
    "print(np.shape(df_test_tmp))\n",
    "\n",
    "df_valid=pd.read_csv(DATAPATH/'valid_labeled.csv')\n",
    "df_valid['is_valid']=1\n",
    "df_tmp = pd.read_csv(DATAPATH/'train_labeled.csv')\n",
    "df_tmp['is_valid']=0\n",
    "df_tmp=pd.concat([df_tmp,df_valid])\n",
    "df_tmp=pd.concat([df_tmp,df_test_tmp])\n",
    "print(np.shape(df_tmp))\n",
    "\n",
    "df_tmp.to_csv(DATAPATH/'df_tmp.csv', index=False)\n",
    "tmplist=TextList.from_csv(DATAPATH, 'df_tmp.csv', cols='content', vocab=data_lm.train_ds.vocab)\n",
    "data_clas_main = (tmplist\n",
    "                .split_from_df(col='is_valid')\n",
    "                .label_from_df(cols='sentiment')#.add_test(test_list)\n",
    "                .databunch(bs=40))\n",
    "\n",
    "learn = text_classifier_learner(data_clas_main, AWD_LSTM)\n",
    "learn.load('main_12e_unfreeze_001')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, slice(1e-5,1e-3), moms=moms)\n",
    "learn.save('main_16e_most_001')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.648263</td>\n",
       "      <td>0.452710</td>\n",
       "      <td>0.816756</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.637243</td>\n",
       "      <td>0.430505</td>\n",
       "      <td>0.828853</td>\n",
       "      <td>01:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.642052</td>\n",
       "      <td>0.435259</td>\n",
       "      <td>0.828405</td>\n",
       "      <td>01:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.638956</td>\n",
       "      <td>0.415244</td>\n",
       "      <td>0.829301</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#add least confident labels\n",
    "\n",
    "#OUTCOME:\n",
    "#Training loss jumps!\n",
    "#validation loss: .423 to .415\n",
    "#But validation accuracy increases!\n",
    "    #81.4 to 82.9\n",
    "    #that's 30% jump towards theoretical maximum of 86.7 (f/ training full large dataset)\n",
    "\n",
    "df_test=pd.read_csv(DATAPATH/'df_unlabeled.csv')\n",
    "df_test_tmp=df_test.iloc[get_these_least]\n",
    "df_test_tmp['is_valid']=0\n",
    "print(np.shape(df_test_tmp))\n",
    "\n",
    "df_valid=pd.read_csv(DATAPATH/'valid_labeled.csv')\n",
    "df_valid['is_valid']=1\n",
    "df_tmp = pd.read_csv(DATAPATH/'train_labeled.csv')\n",
    "df_tmp['is_valid']=0\n",
    "df_tmp=pd.concat([df_tmp,df_valid])\n",
    "df_tmp=pd.concat([df_tmp,df_test_tmp])\n",
    "print(np.shape(df_tmp))\n",
    "\n",
    "df_tmp.to_csv(DATAPATH/'df_tmp.csv', index=False)\n",
    "tmplist=TextList.from_csv(DATAPATH, 'df_tmp.csv', cols='content', vocab=data_lm.train_ds.vocab)\n",
    "data_clas_main = (tmplist\n",
    "                .split_from_df(col='is_valid')\n",
    "                .label_from_df(cols='sentiment')#.add_test(test_list)\n",
    "                .databunch(bs=40))\n",
    "\n",
    "learn = text_classifier_learner(data_clas_main, AWD_LSTM)\n",
    "learn.load('main_12e_unfreeze_001')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, slice(1e-5,1e-3), moms=moms)\n",
    "learn.save('main_16e_least_001')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.561795</td>\n",
       "      <td>0.414618</td>\n",
       "      <td>0.816756</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.563368</td>\n",
       "      <td>0.406196</td>\n",
       "      <td>0.823477</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.558479</td>\n",
       "      <td>0.402578</td>\n",
       "      <td>0.822133</td>\n",
       "      <td>01:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.558469</td>\n",
       "      <td>0.393962</td>\n",
       "      <td>0.825717</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#add somewhat confident labels (centered at .25 and .75)\n",
    "\n",
    "#OUTCOME:\n",
    "#slight increase in training loss\n",
    "#validation loss: .423 to .394\n",
    "#validation accuracy improves somewhat:\n",
    "    #81.4 to 82.6\n",
    "    #~20% jump to theoretical maximum of 86.7\n",
    "\n",
    "df_test=pd.read_csv(DATAPATH/'df_unlabeled.csv')\n",
    "df_test_tmp=df_test.iloc[get_these_somewhat]\n",
    "df_test_tmp['is_valid']=0\n",
    "print(np.shape(df_test_tmp))\n",
    "\n",
    "df_valid=pd.read_csv(DATAPATH/'valid_labeled.csv')\n",
    "df_valid['is_valid']=1\n",
    "df_tmp = pd.read_csv(DATAPATH/'train_labeled.csv')\n",
    "df_tmp['is_valid']=0\n",
    "df_tmp=pd.concat([df_tmp,df_valid])\n",
    "df_tmp=pd.concat([df_tmp,df_test_tmp])\n",
    "print(np.shape(df_tmp))\n",
    "\n",
    "df_tmp.to_csv(DATAPATH/'df_tmp.csv', index=False)\n",
    "tmplist=TextList.from_csv(DATAPATH, 'df_tmp.csv', cols='content', vocab=data_lm.train_ds.vocab)\n",
    "data_clas_main = (tmplist\n",
    "                .split_from_df(col='is_valid')\n",
    "                .label_from_df(cols='sentiment')#.add_test(test_list)\n",
    "                .databunch(bs=40))\n",
    "\n",
    "learn = text_classifier_learner(data_clas_main, AWD_LSTM)\n",
    "learn.load('main_12e_unfreeze_001')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, slice(1e-5,1e-3), moms=moms)\n",
    "learn.save('main_16e_somewhat_001')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.496485</td>\n",
       "      <td>0.410004</td>\n",
       "      <td>0.812276</td>\n",
       "      <td>01:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.474730</td>\n",
       "      <td>0.403703</td>\n",
       "      <td>0.818100</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.473569</td>\n",
       "      <td>0.395176</td>\n",
       "      <td>0.823925</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.456877</td>\n",
       "      <td>0.393547</td>\n",
       "      <td>0.824821</td>\n",
       "      <td>01:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#add random sampling of labels (regardless of confidence)\n",
    "\n",
    "\n",
    "#OUTCOME:\n",
    "#training loss slightly increases but then returns back to baseline\n",
    "#validation loss: .423 to .394\n",
    "#validation accuracy improves somewhat:\n",
    "    #81.4 to 82.5\n",
    "    #~20% jump to theoretical maximum of 86.7\n",
    "\n",
    "df_test=pd.read_csv(DATAPATH/'df_unlabeled.csv')\n",
    "df_test_tmp=df_test.iloc[get_these_rand]\n",
    "df_test_tmp['is_valid']=0\n",
    "print(np.shape(df_test_tmp))\n",
    "\n",
    "df_valid=pd.read_csv(DATAPATH/'valid_labeled.csv')\n",
    "df_valid['is_valid']=1\n",
    "df_tmp = pd.read_csv(DATAPATH/'train_labeled.csv')\n",
    "df_tmp['is_valid']=0\n",
    "df_tmp=pd.concat([df_tmp,df_valid])\n",
    "df_tmp=pd.concat([df_tmp,df_test_tmp])\n",
    "print(np.shape(df_tmp))\n",
    "\n",
    "df_tmp.to_csv(DATAPATH/'df_tmp.csv', index=False)\n",
    "tmplist=TextList.from_csv(DATAPATH, 'df_tmp.csv', cols='content', vocab=data_lm.train_ds.vocab)\n",
    "data_clas_main = (tmplist\n",
    "                .split_from_df(col='is_valid')\n",
    "                .label_from_df(cols='sentiment')#.add_test(test_list)\n",
    "                .databunch(bs=40))\n",
    "\n",
    "learn = text_classifier_learner(data_clas_main, AWD_LSTM)\n",
    "learn.load('main_12e_unfreeze_001')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, slice(1e-5,1e-3), moms=moms)\n",
    "learn.save('main_16e_rand_001')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.630040</td>\n",
       "      <td>0.434415</td>\n",
       "      <td>0.823477</td>\n",
       "      <td>01:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.625436</td>\n",
       "      <td>0.421574</td>\n",
       "      <td>0.823029</td>\n",
       "      <td>01:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.604657</td>\n",
       "      <td>0.410515</td>\n",
       "      <td>0.831541</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.605880</td>\n",
       "      <td>0.405822</td>\n",
       "      <td>0.828853</td>\n",
       "      <td>01:08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#add random sampling of labels in range f/ .25 to .75\n",
    "\n",
    "#OUTCOME:\n",
    "#training loss jumps!\n",
    "#validation loss: .423 to .406\n",
    "#validation accuracy: 81.4 to 82.9\n",
    "    #30% jump towards theoretical maximum of 86.7\n",
    "\n",
    "\n",
    "df_test=pd.read_csv(DATAPATH/'df_unlabeled.csv')\n",
    "df_test_tmp=df_test.iloc[get_these_randsome]\n",
    "df_test_tmp['is_valid']=0\n",
    "print(np.shape(df_test_tmp))\n",
    "\n",
    "df_valid=pd.read_csv(DATAPATH/'valid_labeled.csv')\n",
    "df_valid['is_valid']=1\n",
    "df_tmp = pd.read_csv(DATAPATH/'train_labeled.csv')\n",
    "df_tmp['is_valid']=0\n",
    "df_tmp=pd.concat([df_tmp,df_valid])\n",
    "df_tmp=pd.concat([df_tmp,df_test_tmp])\n",
    "print(np.shape(df_tmp))\n",
    "\n",
    "df_tmp.to_csv(DATAPATH/'df_tmp.csv', index=False)\n",
    "tmplist=TextList.from_csv(DATAPATH, 'df_tmp.csv', cols='content', vocab=data_lm.train_ds.vocab)\n",
    "data_clas_main = (tmplist\n",
    "                .split_from_df(col='is_valid')\n",
    "                .label_from_df(cols='sentiment')#.add_test(test_list)\n",
    "                .databunch(bs=40))\n",
    "\n",
    "learn = text_classifier_learner(data_clas_main, AWD_LSTM)\n",
    "learn.load('main_12e_unfreeze_001')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(4, slice(1e-5,1e-3), moms=moms)\n",
    "learn.save('main_16e_randsome_001')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary:\n",
    "#Best choices are: 1) least confident (closest to 0.5), 2) random sampling bw .25 and .75\n",
    "    #Both produced 30% improvements in accuracy, which is 30% of theoretical maximum\n",
    "#Somewhat effective: 1) random sampling, 2) just values at .25 and .75\n",
    "    #Both produced 20% improvements in accuracy, which is 20% of theoretical maximum\n",
    "#Not effective: most confident\n",
    "    #slight DECREASE in accuracy due to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
